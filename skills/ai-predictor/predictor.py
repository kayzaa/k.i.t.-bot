"""
ðŸ§  K.I.T. AI Market Predictor
=============================
Deep Learning Price Predictions that REPLACE human traders!

Features:
- LSTM with Attention for time series
- Ensemble predictions for robustness
- Confidence scoring with uncertainty estimation
- Real-time feature engineering
"""

import numpy as np
import pandas as pd
from dataclasses import dataclass
from typing import List, Optional, Dict, Tuple
from enum import Enum
import asyncio
import logging
from datetime import datetime, timedelta
import json
import os

# ML Libraries
try:
    import tensorflow as tf
    from tensorflow.keras.models import Sequential, Model, load_model
    from tensorflow.keras.layers import (
        LSTM, Dense, Dropout, Input, Attention,
        LayerNormalization, MultiHeadAttention, GlobalAveragePooling1D
    )
    from tensorflow.keras.optimizers import Adam
    from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
    TF_AVAILABLE = True
except ImportError:
    TF_AVAILABLE = False

try:
    from sklearn.preprocessing import MinMaxScaler, StandardScaler
    from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
    from sklearn.metrics import mean_absolute_error, mean_squared_error
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False

try:
    import xgboost as xgb
    XGB_AVAILABLE = True
except ImportError:
    XGB_AVAILABLE = False

logger = logging.getLogger("kit.ai-predictor")


class PredictionDirection(Enum):
    UP = "UP"
    DOWN = "DOWN"
    NEUTRAL = "NEUTRAL"


@dataclass
class Prediction:
    """Single price prediction result"""
    symbol: str
    timestamp: datetime
    current_price: float
    predicted_price: float
    direction: PredictionDirection
    confidence: float  # 0-1
    low: float  # Lower bound
    high: float  # Upper bound
    horizon_hours: int
    model_used: str
    features_used: List[str]
    
    @property
    def expected_return(self) -> float:
        return (self.predicted_price - self.current_price) / self.current_price
    
    def to_dict(self) -> dict:
        return {
            "symbol": self.symbol,
            "timestamp": self.timestamp.isoformat(),
            "current_price": self.current_price,
            "predicted_price": self.predicted_price,
            "direction": self.direction.value,
            "confidence": self.confidence,
            "range": {"low": self.low, "high": self.high},
            "horizon_hours": self.horizon_hours,
            "expected_return": f"{self.expected_return:.2%}",
            "model": self.model_used
        }


class FeatureEngineer:
    """
    Creates ML features from raw OHLCV data
    50+ technical indicators + custom features
    """
    
    def __init__(self):
        self.feature_names = []
    
    def calculate_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """Calculate all features from OHLCV data"""
        features = pd.DataFrame(index=df.index)
        
        # Price features
        features['returns'] = df['close'].pct_change()
        features['log_returns'] = np.log(df['close'] / df['close'].shift(1))
        features['high_low_ratio'] = df['high'] / df['low']
        features['close_open_ratio'] = df['close'] / df['open']
        
        # Moving Averages
        for period in [7, 14, 21, 50, 100, 200]:
            features[f'sma_{period}'] = df['close'].rolling(period).mean()
            features[f'ema_{period}'] = df['close'].ewm(span=period).mean()
            features[f'price_sma_{period}_ratio'] = df['close'] / features[f'sma_{period}']
        
        # RSI
        for period in [7, 14, 21]:
            delta = df['close'].diff()
            gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
            rs = gain / loss
            features[f'rsi_{period}'] = 100 - (100 / (1 + rs))
        
        # MACD
        exp1 = df['close'].ewm(span=12).mean()
        exp2 = df['close'].ewm(span=26).mean()
        features['macd'] = exp1 - exp2
        features['macd_signal'] = features['macd'].ewm(span=9).mean()
        features['macd_histogram'] = features['macd'] - features['macd_signal']
        
        # Bollinger Bands
        for period in [20, 50]:
            sma = df['close'].rolling(period).mean()
            std = df['close'].rolling(period).std()
            features[f'bb_upper_{period}'] = sma + (std * 2)
            features[f'bb_lower_{period}'] = sma - (std * 2)
            features[f'bb_width_{period}'] = (features[f'bb_upper_{period}'] - features[f'bb_lower_{period}']) / sma
            features[f'bb_position_{period}'] = (df['close'] - features[f'bb_lower_{period}']) / (features[f'bb_upper_{period}'] - features[f'bb_lower_{period}'])
        
        # ATR (Average True Range)
        for period in [14, 21]:
            high_low = df['high'] - df['low']
            high_close = abs(df['high'] - df['close'].shift())
            low_close = abs(df['low'] - df['close'].shift())
            tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
            features[f'atr_{period}'] = tr.rolling(period).mean()
            features[f'atr_{period}_pct'] = features[f'atr_{period}'] / df['close']
        
        # Volume features
        features['volume_sma_20'] = df['volume'].rolling(20).mean()
        features['volume_ratio'] = df['volume'] / features['volume_sma_20']
        features['volume_change'] = df['volume'].pct_change()
        
        # OBV (On-Balance Volume)
        obv = (np.sign(df['close'].diff()) * df['volume']).cumsum()
        features['obv'] = obv
        features['obv_sma'] = obv.rolling(20).mean()
        
        # Momentum
        for period in [5, 10, 20]:
            features[f'momentum_{period}'] = df['close'] / df['close'].shift(period) - 1
        
        # Stochastic
        for period in [14, 21]:
            low_min = df['low'].rolling(period).min()
            high_max = df['high'].rolling(period).max()
            features[f'stoch_k_{period}'] = 100 * (df['close'] - low_min) / (high_max - low_min)
            features[f'stoch_d_{period}'] = features[f'stoch_k_{period}'].rolling(3).mean()
        
        # Williams %R
        features['williams_r'] = -100 * (df['high'].rolling(14).max() - df['close']) / (df['high'].rolling(14).max() - df['low'].rolling(14).min())
        
        # CCI (Commodity Channel Index)
        typical_price = (df['high'] + df['low'] + df['close']) / 3
        features['cci'] = (typical_price - typical_price.rolling(20).mean()) / (0.015 * typical_price.rolling(20).std())
        
        # ADX (Average Directional Index)
        plus_dm = df['high'].diff()
        minus_dm = df['low'].diff()
        plus_dm[plus_dm < 0] = 0
        minus_dm[minus_dm > 0] = 0
        
        tr = pd.concat([
            df['high'] - df['low'],
            abs(df['high'] - df['close'].shift()),
            abs(df['low'] - df['close'].shift())
        ], axis=1).max(axis=1)
        
        atr_14 = tr.rolling(14).mean()
        plus_di = 100 * (plus_dm.rolling(14).mean() / atr_14)
        minus_di = 100 * (abs(minus_dm).rolling(14).mean() / atr_14)
        features['adx'] = 100 * abs(plus_di - minus_di) / (plus_di + minus_di)
        features['adx'] = features['adx'].rolling(14).mean()
        
        # Volatility
        features['volatility_20'] = features['returns'].rolling(20).std() * np.sqrt(365 * 24)
        features['volatility_50'] = features['returns'].rolling(50).std() * np.sqrt(365 * 24)
        
        # Price patterns
        features['higher_high'] = (df['high'] > df['high'].shift(1)).astype(int)
        features['lower_low'] = (df['low'] < df['low'].shift(1)).astype(int)
        features['inside_bar'] = ((df['high'] < df['high'].shift(1)) & (df['low'] > df['low'].shift(1))).astype(int)
        
        # Candle patterns
        body = abs(df['close'] - df['open'])
        wick_upper = df['high'] - df[['close', 'open']].max(axis=1)
        wick_lower = df[['close', 'open']].min(axis=1) - df['low']
        features['body_size'] = body / df['close']
        features['upper_wick_ratio'] = wick_upper / (body + 0.0001)
        features['lower_wick_ratio'] = wick_lower / (body + 0.0001)
        features['doji'] = (body / (df['high'] - df['low'] + 0.0001) < 0.1).astype(int)
        
        # Time features (if datetime index)
        if isinstance(df.index, pd.DatetimeIndex):
            features['hour'] = df.index.hour
            features['day_of_week'] = df.index.dayofweek
            features['is_weekend'] = (df.index.dayofweek >= 5).astype(int)
        
        self.feature_names = list(features.columns)
        
        return features.replace([np.inf, -np.inf], np.nan).dropna()


class LSTMPredictor:
    """
    LSTM Neural Network with Attention for price prediction
    """
    
    def __init__(
        self,
        lookback: int = 168,
        units: List[int] = [128, 64, 32],
        dropout: float = 0.2,
        learning_rate: float = 0.001
    ):
        self.lookback = lookback
        self.units = units
        self.dropout = dropout
        self.learning_rate = learning_rate
        self.model = None
        self.scaler_X = MinMaxScaler()
        self.scaler_y = MinMaxScaler()
        self.is_trained = False
        
    def build_model(self, n_features: int) -> Model:
        """Build LSTM model with attention"""
        if not TF_AVAILABLE:
            raise ImportError("TensorFlow required for LSTM model")
        
        inputs = Input(shape=(self.lookback, n_features))
        
        # First LSTM layer
        x = LSTM(self.units[0], return_sequences=True)(inputs)
        x = LayerNormalization()(x)
        x = Dropout(self.dropout)(x)
        
        # Attention layer
        attention = MultiHeadAttention(num_heads=4, key_dim=32)(x, x)
        x = x + attention  # Residual connection
        x = LayerNormalization()(x)
        
        # Second LSTM layer
        x = LSTM(self.units[1], return_sequences=True)(x)
        x = Dropout(self.dropout)(x)
        
        # Third LSTM layer
        x = LSTM(self.units[2], return_sequences=False)(x)
        x = Dropout(self.dropout)(x)
        
        # Dense layers
        x = Dense(32, activation='relu')(x)
        x = Dropout(self.dropout)(x)
        
        # Output: price prediction + uncertainty
        price_output = Dense(1, name='price')(x)
        
        model = Model(inputs=inputs, outputs=price_output)
        model.compile(
            optimizer=Adam(learning_rate=self.learning_rate),
            loss='huber',  # Robust to outliers
            metrics=['mae']
        )
        
        return model
    
    def prepare_sequences(
        self,
        features: np.ndarray,
        targets: np.ndarray
    ) -> Tuple[np.ndarray, np.ndarray]:
        """Create sequences for LSTM training"""
        X, y = [], []
        
        for i in range(self.lookback, len(features)):
            X.append(features[i-self.lookback:i])
            y.append(targets[i])
        
        return np.array(X), np.array(y)
    
    def train(
        self,
        features: pd.DataFrame,
        targets: pd.Series,
        validation_split: float = 0.2,
        epochs: int = 100,
        batch_size: int = 32
    ) -> dict:
        """Train the LSTM model"""
        # Scale features
        X_scaled = self.scaler_X.fit_transform(features.values)
        y_scaled = self.scaler_y.fit_transform(targets.values.reshape(-1, 1))
        
        # Create sequences
        X, y = self.prepare_sequences(X_scaled, y_scaled)
        
        # Build model
        self.model = self.build_model(features.shape[1])
        
        # Callbacks
        callbacks = [
            EarlyStopping(patience=10, restore_best_weights=True),
            ModelCheckpoint('best_model.keras', save_best_only=True)
        ]
        
        # Train
        history = self.model.fit(
            X, y,
            validation_split=validation_split,
            epochs=epochs,
            batch_size=batch_size,
            callbacks=callbacks,
            verbose=1
        )
        
        self.is_trained = True
        
        return {
            'final_loss': history.history['loss'][-1],
            'final_val_loss': history.history['val_loss'][-1],
            'epochs_trained': len(history.history['loss'])
        }
    
    def predict(self, features: pd.DataFrame) -> Tuple[float, float]:
        """Make prediction with uncertainty estimation using MC Dropout"""
        if not self.is_trained:
            raise ValueError("Model not trained yet")
        
        X_scaled = self.scaler_X.transform(features.values)
        X_seq = X_scaled[-self.lookback:].reshape(1, self.lookback, -1)
        
        # Monte Carlo Dropout for uncertainty
        predictions = []
        for _ in range(50):  # 50 forward passes
            pred = self.model(X_seq, training=True)  # Keep dropout active
            predictions.append(pred.numpy()[0, 0])
        
        predictions = np.array(predictions)
        mean_pred = self.scaler_y.inverse_transform([[predictions.mean()]])[0, 0]
        std_pred = predictions.std()
        
        # Confidence based on uncertainty
        confidence = max(0, 1 - (std_pred * 2))  # Lower std = higher confidence
        
        return mean_pred, confidence


class EnsemblePredictor:
    """
    Ensemble of multiple models for robust predictions
    """
    
    def __init__(self):
        self.models = {}
        self.weights = {}
        
    def add_xgboost(self):
        """Add XGBoost regressor"""
        if not XGB_AVAILABLE:
            return
        
        self.models['xgboost'] = xgb.XGBRegressor(
            n_estimators=100,
            max_depth=6,
            learning_rate=0.1,
            objective='reg:squarederror',
            verbosity=0
        )
        self.weights['xgboost'] = 0.3
    
    def add_random_forest(self):
        """Add Random Forest regressor"""
        if not SKLEARN_AVAILABLE:
            return
        
        self.models['random_forest'] = RandomForestRegressor(
            n_estimators=100,
            max_depth=10,
            n_jobs=-1
        )
        self.weights['random_forest'] = 0.2
    
    def add_gradient_boosting(self):
        """Add Gradient Boosting regressor"""
        if not SKLEARN_AVAILABLE:
            return
        
        self.models['gradient_boosting'] = GradientBoostingRegressor(
            n_estimators=100,
            max_depth=5,
            learning_rate=0.1
        )
        self.weights['gradient_boosting'] = 0.2
    
    def train(self, X: np.ndarray, y: np.ndarray):
        """Train all ensemble models"""
        for name, model in self.models.items():
            logger.info(f"Training {name}...")
            model.fit(X, y)
    
    def predict(self, X: np.ndarray) -> Tuple[float, float]:
        """Weighted ensemble prediction"""
        predictions = []
        total_weight = 0
        
        for name, model in self.models.items():
            pred = model.predict(X.reshape(1, -1))[0]
            weight = self.weights[name]
            predictions.append((pred, weight))
            total_weight += weight
        
        # Weighted average
        weighted_pred = sum(p * w for p, w in predictions) / total_weight
        
        # Confidence based on agreement between models
        preds_only = [p for p, _ in predictions]
        std = np.std(preds_only) if len(preds_only) > 1 else 0
        confidence = max(0, 1 - (std / (abs(weighted_pred) + 0.0001)))
        
        return weighted_pred, confidence


class MarketPredictor:
    """
    Main class for K.I.T. AI Market Predictions
    Combines LSTM + Ensemble for maximum accuracy
    """
    
    def __init__(self, config: Optional[dict] = None):
        self.config = config or {}
        self.feature_engineer = FeatureEngineer()
        self.lstm = LSTMPredictor()
        self.ensemble = EnsemblePredictor()
        
        # Initialize ensemble models
        self.ensemble.add_xgboost()
        self.ensemble.add_random_forest()
        self.ensemble.add_gradient_boosting()
        
        # Cache for trained models
        self.trained_symbols = {}
        
    async def fetch_data(
        self,
        symbol: str,
        timeframe: str = "1h",
        limit: int = 500
    ) -> pd.DataFrame:
        """Fetch OHLCV data from exchange"""
        # This would connect to exchange-connector skill
        # For now, return placeholder
        logger.info(f"Fetching {limit} candles for {symbol} ({timeframe})")
        
        # Placeholder - would call exchange API
        # df = await exchange.fetch_ohlcv(symbol, timeframe, limit)
        
        return pd.DataFrame()
    
    async def predict(
        self,
        symbol: str,
        timeframe: str = "1h",
        horizon: int = 24,
        use_lstm: bool = True,
        use_ensemble: bool = True
    ) -> Prediction:
        """
        Generate price prediction for a symbol
        
        Args:
            symbol: Trading pair (e.g., "BTC/USDT")
            timeframe: Candle timeframe
            horizon: Hours to predict ahead
            use_lstm: Use LSTM neural network
            use_ensemble: Use ensemble models
            
        Returns:
            Prediction object with price, direction, confidence
        """
        logger.info(f"ðŸ”® Predicting {symbol} {horizon}h ahead...")
        
        # Fetch data
        df = await self.fetch_data(symbol, timeframe, limit=500)
        
        if df.empty:
            # Demo mode with synthetic data
            logger.warning("Using demo mode with synthetic data")
            np.random.seed(42)
            n = 500
            df = pd.DataFrame({
                'timestamp': pd.date_range(end=datetime.now(), periods=n, freq='1h'),
                'open': 50000 + np.cumsum(np.random.randn(n) * 100),
                'high': 0,
                'low': 0,
                'close': 0,
                'volume': np.random.uniform(100, 1000, n)
            })
            df['close'] = df['open'] + np.random.randn(n) * 50
            df['high'] = df[['open', 'close']].max(axis=1) + np.random.uniform(0, 100, n)
            df['low'] = df[['open', 'close']].min(axis=1) - np.random.uniform(0, 100, n)
            df.set_index('timestamp', inplace=True)
        
        # Feature engineering
        features = self.feature_engineer.calculate_features(df)
        current_price = df['close'].iloc[-1]
        
        predictions = []
        confidences = []
        
        # LSTM prediction
        if use_lstm and TF_AVAILABLE:
            try:
                if symbol not in self.trained_symbols:
                    # Train on historical data
                    targets = df['close'].iloc[len(df) - len(features):]
                    self.lstm.train(features, targets, epochs=50)
                    self.trained_symbols[symbol] = True
                
                lstm_pred, lstm_conf = self.lstm.predict(features)
                predictions.append(lstm_pred)
                confidences.append(lstm_conf)
                logger.info(f"LSTM: ${lstm_pred:.2f} (conf: {lstm_conf:.1%})")
            except Exception as e:
                logger.error(f"LSTM prediction failed: {e}")
        
        # Ensemble prediction
        if use_ensemble and SKLEARN_AVAILABLE:
            try:
                X = features.values
                y = df['close'].iloc[len(df) - len(features):].values
                self.ensemble.train(X[:-horizon], y[:-horizon])
                
                ens_pred, ens_conf = self.ensemble.predict(X[-1])
                predictions.append(ens_pred)
                confidences.append(ens_conf)
                logger.info(f"Ensemble: ${ens_pred:.2f} (conf: {ens_conf:.1%})")
            except Exception as e:
                logger.error(f"Ensemble prediction failed: {e}")
        
        # Combine predictions
        if predictions:
            final_price = np.mean(predictions)
            final_confidence = np.mean(confidences)
        else:
            # Fallback: simple momentum
            momentum = df['close'].pct_change(horizon).iloc[-1]
            final_price = current_price * (1 + momentum)
            final_confidence = 0.3
        
        # Determine direction
        price_change = (final_price - current_price) / current_price
        if price_change > 0.01:
            direction = PredictionDirection.UP
        elif price_change < -0.01:
            direction = PredictionDirection.DOWN
        else:
            direction = PredictionDirection.NEUTRAL
        
        # Calculate prediction range
        volatility = df['close'].pct_change().std() * np.sqrt(horizon)
        low = final_price * (1 - volatility * 2)
        high = final_price * (1 + volatility * 2)
        
        prediction = Prediction(
            symbol=symbol,
            timestamp=datetime.now(),
            current_price=current_price,
            predicted_price=final_price,
            direction=direction,
            confidence=final_confidence,
            low=low,
            high=high,
            horizon_hours=horizon,
            model_used="LSTM+Ensemble" if (use_lstm and use_ensemble) else "LSTM" if use_lstm else "Ensemble",
            features_used=self.feature_engineer.feature_names[:10]  # Top 10
        )
        
        logger.info(f"âœ… Prediction: {direction.value} to ${final_price:.2f} ({final_confidence:.1%} conf)")
        
        return prediction
    
    async def predict_batch(
        self,
        symbols: List[str],
        timeframe: str = "1h",
        horizon: int = 24
    ) -> List[Prediction]:
        """Predict multiple symbols in parallel"""
        tasks = [
            self.predict(symbol, timeframe, horizon)
            for symbol in symbols
        ]
        return await asyncio.gather(*tasks)
    
    def get_top_predictions(
        self,
        predictions: List[Prediction],
        min_confidence: float = 0.6,
        direction: Optional[PredictionDirection] = None
    ) -> List[Prediction]:
        """Filter and sort predictions by confidence"""
        filtered = [p for p in predictions if p.confidence >= min_confidence]
        
        if direction:
            filtered = [p for p in filtered if p.direction == direction]
        
        return sorted(filtered, key=lambda p: p.confidence, reverse=True)


# CLI Demo
if __name__ == "__main__":
    import asyncio
    import sys
    
    # Fix Windows encoding
    if sys.platform == 'win32':
        try:
            sys.stdout.reconfigure(encoding='utf-8')
        except:
            pass
    
    async def demo():
        print("[AI] K.I.T. AI Market Predictor Demo")
        print("=" * 50)
        
        predictor = MarketPredictor()
        
        # Check available backends
        backends = []
        if TF_AVAILABLE:
            backends.append("TensorFlow/LSTM")
        if SKLEARN_AVAILABLE:
            backends.append("sklearn (RF+GB)")
        if XGB_AVAILABLE:
            backends.append("XGBoost")
        print(f"[INFO] Available backends: {', '.join(backends) or 'None!'}")
        
        # Single prediction
        pred = await predictor.predict(
            symbol="BTC/USDT",
            timeframe="1h",
            horizon=24,
            use_lstm=TF_AVAILABLE,
            use_ensemble=SKLEARN_AVAILABLE
        )
        
        print("\n[PREDICT] BTC/USDT 24h Prediction:")
        print(json.dumps(pred.to_dict(), indent=2, default=str))
        
        # Batch predictions
        symbols = ["BTC/USDT", "ETH/USDT", "SOL/USDT"]
        predictions = await predictor.predict_batch(symbols, horizon=24)
        
        print("\n[BATCH] Predictions:")
        for p in predictions:
            print(f"  {p.symbol}: {p.direction.value} to ${p.predicted_price:.2f} ({p.confidence:.1%})")
        
        # Top picks
        top = predictor.get_top_predictions(predictions, min_confidence=0.5)
        print(f"\n[TOP] Picks (>50% confidence): {len(top)}")
        
        print("\n[SUCCESS] AI Predictor ready for production!")
    
    asyncio.run(demo())
